{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diminutive Suffix Productivity: corpus processing and cleaning\n",
    "Juan Berrios | jeb358@pitt.edu | Last updated: March 19, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary and overview of the data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The purpose of the code included in this notebook is to build `DataFrame` objects from the `.txt` files in the corpus directories. I also do some preliminary data cleaning. The corpus I am using is the [*Corpus del español*](https://www.corpusdelespanol.org/); more specifically the [Web/Dialects](https://www.corpusdelespanol.org/web-dial/) corpus. While the corpus is searchable online, it is also possible to access the full data set for those wishing to do computational analyses, such as this. It is necessary to purchase a license to do so. I am authorized to use it through the license of the [Department of Linguistics](https://www.linguistics.pitt.edu/). Samples for the different formats can be downloaded from the [official website](https://www.corpusdata.org/formats.asp). I have also uploaded a copy of the free sample in the [data samples  directory](https://github.com/Data-Science-for-Linguists-2020/Diminutive-Suffix-Productivity/tree/master/data_samples) of this repository. The data set is available in three formats: (i) Database (Structured Query Language), (ii) Word/lemma/PoS, and (iii) linear (raw) text. All are `.txt` files and the former two are tab-delimited. I have chosen to work with the second format because the tags will come in handy and because it's quite compatible with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "1. [Preparation](#1.-Preparation)  includes the necessary preparations.\n",
    "2. [Loading files](#2.-Loading-files)  includes code for loading the files and turning them into data frames using one of the `.txt` file as a sample.\n",
    "3. [Processing corpus directories](#3.-Processing-corpus-directories)  includes code for performing the operations on a corpus directory containing all the text files of one variety.\n",
    "4. [Storing files](#4.-Storing-files)  includes code for storing the resulting data frames as pickled files.\n",
    "5. [Alternative code](#5.-Alternative-code)  includes alternative code to accomplish some of the tasks in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading libraries and additional settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import glob, pickle, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Turning pretty print off:\n",
    "%pprint\n",
    "\n",
    "#Releasing all output:                                            \n",
    "from IPython.core.interactiveshell import InteractiveShell #Prints all commands rather than the last one.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `txt` files are very large. For testing purposes, I'll use only one of them as a start. The files are also tab-delimited, which makes my job a little easier. The columns correspond to an ID for the source text, an ID for the token, the token (word), the lemma, and the POS. I will hence use those for column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../Diminutive-Suffix-Productivity/private/data/wlp_ES-sbo/es-b-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SourceID', 'TokenID', 'Word', 'Lemma', 'POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First row is ignored because it corresponds to an identifier for the .txt file.\n",
    "\n",
    "df = pd.read_csv(fname,sep='\\t',encoding ='iso-8859-1',skiprows=[0],header=None,names=cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #Removing NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27310829, 5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #It's a very large file (27345213 rows). It will get much smaller once I start cleaning up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SourceID     TokenID  Word Lemma      POS\n",
       "0    431270  2206403096  Este  este      dd-\n",
       "1    431270  2206403097    es   ser   vip-3s\n",
       "2    431270  2206403098    un    un    li-ms\n",
       "3    431270  2206403099  blog  blog  nms    \n",
       "4    431270  2206403100    de    de        e"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)   #The lemma column will be useful when I need to aggregations that put lowecase and uppercase \n",
    "            #as well as plural and singular forms together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345212</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862347</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "27345212    676060  2511862347                         .   \n",
       "\n",
       "                             Lemma       POS  \n",
       "27345208                       mas        cc  \n",
       "27345209               información         n  \n",
       "27345210                   visitar  vsp-1/3s  \n",
       "27345211  www.dineroabundancia.com         n  \n",
       "27345212                        $.         y  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>8330253</td>\n",
       "      <td>517950</td>\n",
       "      <td>1671391719</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17322104</td>\n",
       "      <td>589480</td>\n",
       "      <td>398554469</td>\n",
       "      <td>,</td>\n",
       "      <td>$,</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6715455</td>\n",
       "      <td>496570</td>\n",
       "      <td>650290440</td>\n",
       "      <td>orígenes</td>\n",
       "      <td>origen</td>\n",
       "      <td>nmp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19091258</td>\n",
       "      <td>598950</td>\n",
       "      <td>1679652522</td>\n",
       "      <td>se</td>\n",
       "      <td>se</td>\n",
       "      <td>po</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21918216</td>\n",
       "      <td>623720</td>\n",
       "      <td>2272201126</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID      Word   Lemma      POS\n",
       "8330253     517950  1671391719        no      no        r\n",
       "17322104    589480   398554469         ,      $,        y\n",
       "6715455     496570   650290440  orígenes  origen  nmp    \n",
       "19091258    598950  1679652522        se      se       po\n",
       "21918216    623720  2272201126        un      un    li-ms"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5) #Everything seems to be loaded correctly as of now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dd-', 'vip-3s', 'li-ms', 'nms    ', 'e', 'nfp    ', 'y',\n",
       "       'nfs    ', 'nmp    ', 'vsp-1/3s', 'n', 'cc', 'o', 'r', 'vps-ms',\n",
       "       'ld-fs', 'm$', 'vc-1/3s', 'vr', 'po', 'li-fs', 'ld-mp', 'vip-3p',\n",
       "       'ld-ms', 'jms    ', 'vpp', 'mc', 'vps-fs', 'j', 'vii-1/3s', 'e_21',\n",
       "       'x', 'cs', 'ld', 'v', 'cc-', 'ld-fp', 'pi-0cn', 'dd', 'dxmp-ind-',\n",
       "       'vip-2s', 'dp-', 'vsp-3p', 'pi-0ms', 'jfp    ', 'cS_21', 'cS_22',\n",
       "       'jmp    ', 'vsp-2s', 'vip-1s', 'vsp-1p', 'ps', 'vip-1p/vis-1p',\n",
       "       'vip-1p', 'pd-3cs', 'vif-1p', 'vps-mp', 'vif-3s', 'vif-3p',\n",
       "       'jfs    ', 'dxfs-ind-', 'vsj-1/3s', 'i', 'pi-3ms', 'vis-3s', 'b',\n",
       "       'p', 'np', 'pr-3cn\"', 'px', 'dxms-ind-', 'pi-3cs', 'dxfs-',\n",
       "       'pr-3cs', 'px-ms', 'dxfp-ind-', 'vis-3p', 'li-mp', 'pi', 'vsi-3p',\n",
       "       'px-mp', 'vsi-1/3s', 'pq-3cn\"', 'vif-2s', 'vif-2p', 'vsp-2p',\n",
       "       'vip-2p', 'vpp-00', 'vm-2p', 'vis-1p', 'dxcs-ind-', 'pr-3cp',\n",
       "       'dxcs-dem-', 'vif-1s', 'vc-1p', 'cC_21', 'cC_22', 'vps-fp',\n",
       "       'vii-3p', 'pq-3cn', 'e_32', 'vis-1s', 'pr-0mp', 'pr-3fs', 'vc-3p',\n",
       "       'vii-1p', 'pv', 'nj', 'fn', 'vc-2p', 'vsi-2s', 'li-fp', 'pp-1cs',\n",
       "       'dxfp-', 'vsi-1p', 'vii-2s', 'vis-2s', 'pr-3ms', 'e_22', 'mo-ms-',\n",
       "       'jn', 'pr-3mp', 'cS_31', 'cS_32', 'cS_33', 'pq-3cp', 'dxfp-int-',\n",
       "       'vii-2p', 'vsj-3p', 'pp-2cs', 'vm-2s', 'pp-2cp', 'fj', 'mo',\n",
       "       'pr-3fs\"', 'pq-3cs', 'f', 'dxcp-dem-', 'e_43', 'vm-3p', 'fv',\n",
       "       'vc-2s', 'pq-3ms', 'fp', 'pron', 'prep', 'mo-fs-', 'pr-3fp',\n",
       "       'vis-2p', 'vm-3s', 'vsf-1/3s', 'e_31', 'vsi-2p', 'mo-mp-', 'N',\n",
       "       'pd-3ms', 'vsj-1p', 'xp', 'dxmp-int-', 'xs', 'xx', 'vsj-2s', 'fx',\n",
       "       'cS_41', 'cS_42', 'cS_43', 'cS_44', 'vsf-3p', 'e_33', 'px-00',\n",
       "       'vsj-2p', 'e_42', 'fnp', 'x_sp', 'pp-2p', 'fnj', 'xe', 'dxfs-int-',\n",
       "       'vsf-2s', 'dxcp-ind-', 'pd-3fs', 'pd-3fp', 'pd-3mp', 'PN_MISC',\n",
       "       'v51    ', 'li', 'de', 'mo-fp-', 'fe', 'xb', 'v29    ', 'v30    ',\n",
       "       'vsf-2p', 'dp', 'ADJ', 'pn', 'xa', 'xy', 'xw', 'm', 'xh', 'xd',\n",
       "       'vsf-1p', 'vsp-', 'a', 'xm'], dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POS'].unique()  #These POS tags are not very transparent, but it's a good start. These will also come \n",
    "                    #handy for data clean up because diminutivization applies only to some classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Variety'] = 'ES' #Time to add a column for the variety of Spanish. In this case Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SourceID     TokenID  Word Lemma      POS Variety\n",
       "0    431270  2206403096  Este  este      dd-      ES\n",
       "1    431270  2206403097    es   ser   vip-3s      ES\n",
       "2    431270  2206403098    un    un    li-ms      ES\n",
       "3    431270  2206403099  blog  blog  nms          ES\n",
       "4    431270  2206403100    de    de        e      ES"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #It works out well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345212</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862347</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "27345212    676060  2511862347                         .   \n",
       "\n",
       "                             Lemma       POS Variety  \n",
       "27345208                       mas        cc      ES  \n",
       "27345209               información         n      ES  \n",
       "27345210                   visitar  vsp-1/3s      ES  \n",
       "27345211  www.dineroabundancia.com         n      ES  \n",
       "27345212                        $.         y      ES  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24403218</td>\n",
       "      <td>649640</td>\n",
       "      <td>834060125</td>\n",
       "      <td>que</td>\n",
       "      <td>que</td>\n",
       "      <td>cs</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3669217</td>\n",
       "      <td>471560</td>\n",
       "      <td>619788564</td>\n",
       "      <td>segundo</td>\n",
       "      <td>segundo</td>\n",
       "      <td>mc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6426100</td>\n",
       "      <td>495270</td>\n",
       "      <td>2027468388</td>\n",
       "      <td>angoleño</td>\n",
       "      <td>angoleño</td>\n",
       "      <td>jms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17556588</td>\n",
       "      <td>590800</td>\n",
       "      <td>2468531832</td>\n",
       "      <td>diferentes</td>\n",
       "      <td>diferente</td>\n",
       "      <td>jmp</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21936826</td>\n",
       "      <td>624200</td>\n",
       "      <td>2649604048</td>\n",
       "      <td>haber</td>\n",
       "      <td>haber</td>\n",
       "      <td>v</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID        Word      Lemma      POS Variety\n",
       "24403218    649640   834060125         que        que       cs      ES\n",
       "3669217     471560   619788564     segundo    segundo       mc      ES\n",
       "6426100     495270  2027468388    angoleño   angoleño  jms          ES\n",
       "17556588    590800  2468531832  diferentes  diferente  jmp          ES\n",
       "21936826    624200  2649604048       haber      haber        v      ES"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A first step involved in cleaning up the data is to remove rows that are not necessary for this analysis. There are two main things to tackle first: symbols and '@' that are stand-ins for words that were removed from the corpus for copyright reasons when it was created. For the former, I can make use of the POS column. Symbols are tagged 'y'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['POS'] != 'y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345207</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862342</td>\n",
       "      <td>obtener</td>\n",
       "      <td>obtener</td>\n",
       "      <td>vr</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24184571 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "0           431270  2206403096                      Este   \n",
       "1           431270  2206403097                        es   \n",
       "2           431270  2206403098                        un   \n",
       "3           431270  2206403099                      blog   \n",
       "4           431270  2206403100                        de   \n",
       "...            ...         ...                       ...   \n",
       "27345207    676060  2511862342                   obtener   \n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "\n",
       "                             Lemma       POS Variety  \n",
       "0                             este       dd-      ES  \n",
       "1                              ser    vip-3s      ES  \n",
       "2                               un     li-ms      ES  \n",
       "3                             blog   nms          ES  \n",
       "4                               de         e      ES  \n",
       "...                            ...       ...     ...  \n",
       "27345207                   obtener        vr      ES  \n",
       "27345208                       mas        cc      ES  \n",
       "27345209               información         n      ES  \n",
       "27345210                   visitar  vsp-1/3s      ES  \n",
       "27345211  www.dineroabundancia.com         n      ES  \n",
       "\n",
       "[24184571 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #It works. Looks like around 3,000,000 rows were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since '@' is meant to replace words and not symbols, it is tagged as a noun, so the same strategy doesn't work. An alternative is to use the Word column instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Word'] != '@'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345207</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862342</td>\n",
       "      <td>obtener</td>\n",
       "      <td>obtener</td>\n",
       "      <td>vr</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22924607 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "0           431270  2206403096                      Este   \n",
       "1           431270  2206403097                        es   \n",
       "2           431270  2206403098                        un   \n",
       "3           431270  2206403099                      blog   \n",
       "4           431270  2206403100                        de   \n",
       "...            ...         ...                       ...   \n",
       "27345207    676060  2511862342                   obtener   \n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "\n",
       "                             Lemma       POS Variety  \n",
       "0                             este       dd-      ES  \n",
       "1                              ser    vip-3s      ES  \n",
       "2                               un     li-ms      ES  \n",
       "3                             blog   nms          ES  \n",
       "4                               de         e      ES  \n",
       "...                            ...       ...     ...  \n",
       "27345207                   obtener        vr      ES  \n",
       "27345208                       mas        cc      ES  \n",
       "27345209               información         n      ES  \n",
       "27345210                   visitar  vsp-1/3s      ES  \n",
       "27345211  www.dineroabundancia.com         n      ES  \n",
       "\n",
       "[22924607 rows x 6 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #Looks good, this removed about 1,500,000 more rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lastly, I only want to keep diminutivized forms for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Word'].str.contains(r'\\w*i(t|ll)(o|a)s?\\b', regex=True)]    #Keeps only rows ending in the segments of interest.\n",
    "\n",
    "\n",
    "#df = df[(df['Word'].str[-3:] == 'ito') | (df['Word'].str[-3:] == 'ita')|   #Former code\n",
    "#  (df['Word'].str[-4:] == 'itos') | (df['Word'].str[-4:] == 'itas')|   \n",
    "#  (df['Word'].str[-4:] == 'illo') | (df['Word'].str[-4:] == 'illa')|       \n",
    "#  (df['Word'].str[-4:] == 'illos') | (df['Word'].str[-4:] == 'illas')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403194</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>nikita</td>\n",
       "      <td>o</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403206</td>\n",
       "      <td>escrito</td>\n",
       "      <td>escrito</td>\n",
       "      <td>jms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527333</td>\n",
       "      <td>calladita</td>\n",
       "      <td>calladito</td>\n",
       "      <td>j</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527343</td>\n",
       "      <td>sólito</td>\n",
       "      <td>sólito</td>\n",
       "      <td>jms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>431310</td>\n",
       "      <td>2143630275</td>\n",
       "      <td>necesita</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344546</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005820</td>\n",
       "      <td>depósitos</td>\n",
       "      <td>depósito</td>\n",
       "      <td>nmp</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344657</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005931</td>\n",
       "      <td>precipita</td>\n",
       "      <td>precipitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344674</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005948</td>\n",
       "      <td>corralito</td>\n",
       "      <td>corralito</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344789</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511861924</td>\n",
       "      <td>sencillos</td>\n",
       "      <td>sencillo</td>\n",
       "      <td>j</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345089</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862224</td>\n",
       "      <td>permita</td>\n",
       "      <td>permitir</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103923 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID       Word       Lemma       POS Variety\n",
       "98          431270  2206403194     Nikita      nikita         o      ES\n",
       "110         431270  2206403206    escrito     escrito   jms          ES\n",
       "321         431290  2074527333  calladita   calladito         j      ES\n",
       "331         431290  2074527343     sólito      sólito   jms          ES\n",
       "536         431310  2143630275   necesita   necesitar    vip-3s      ES\n",
       "...            ...         ...        ...         ...       ...     ...\n",
       "27344546    676040   250005820  depósitos    depósito   nmp          ES\n",
       "27344657    676040   250005931  precipita  precipitar    vip-3s      ES\n",
       "27344674    676040   250005948  corralito   corralito         n      ES\n",
       "27344789    676060  2511861924  sencillos    sencillo         j      ES\n",
       "27345089    676060  2511862224    permita    permitir  vsp-1/3s      ES\n",
       "\n",
       "[103923 rows x 6 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This gets the data at to a first stage that's easier to work with. There are still many rows which do not belong in the data frame (e.g., verb forms other than gerunds that just happen to end in the same segment), but it will be more efficient to remove those when the full data frame is constructed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing corpus directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a first step, knowing now that the operations above are sucessful, I will define functions to make the processing pipeline for the full data drame object more efficient and streamlined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDF(fname):\n",
    "    \"\"\"Turns tab-delimited file into a data frame\"\"\"\n",
    "    cols = ['SourceID', 'TokenID', 'Word', 'Lemma', 'POS']\n",
    "    df = pd.read_csv(fname,sep='\\t',encoding ='iso-8859-1',skiprows=[0],header=None,names=cols)\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variety(df,variety):\n",
    "    \"\"\"Adds a column specifying a given variety of Spanish to a data frame\"\"\"\n",
    "    df['Variety'] = variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_syms(df):\n",
    "    \"\"\"Excludes symbols\"\"\"\n",
    "    df = df[df['POS'] != 'y']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redacted(df):\n",
    "    \"\"\"Excludes @ symbols, which stand for words that have been redacted for copyright reasons\"\"\"\n",
    "    df = df[df['Word'] != '@']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nondims(df):\n",
    "    \"\"\"Removes tokens that do not end in the segments of interest (-ito/-illo)\"\"\"\n",
    "    df = df[df['Word'].str.contains(r'\\w*i(t|ll)(o|a)s?\\b', regex=True)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's set the directory. I'll start with the Spain directory, since I used a Spain text file for the test run in Section 2 above. In addition, Spain is by far the largest directory (over 3 GB when compressed), so if the code works fine for it, it should work for the rest of the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Diminutive-Suffix-Productivity/private/data/wlp_ES-sbo\\\\es-b-0.txt'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dir = '../../Diminutive-Suffix-Productivity/private/data/'\n",
    "es_dir = glob.glob(corpus_dir + 'wlp_ES-sbo/*.txt')\n",
    "es_dir[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(es_fname) #There are 20 files in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SourceID, TokenID, Word, Lemma, POS]\n",
       "Index: []"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_DF = pd.DataFrame(columns=cols) #Builds a new, empty data frame object.\n",
    "es_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in es_fname:                         #Note that I'm only using one of the cleaning functions\n",
    "    df = toDF(fname)                           #because it gets me to the same end result. But the other ones   \n",
    "    df = remove_nondims(df)                    #might be useful down the road, which is why I defined them.\n",
    "    es_DF = pd.concat([es_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>nikita</td>\n",
       "      <td>o</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403194</td>\n",
       "      <td>Nikita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>escrito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403206</td>\n",
       "      <td>escrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>calladito</td>\n",
       "      <td>j</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527333</td>\n",
       "      <td>calladita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>sólito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527343</td>\n",
       "      <td>sólito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>431310</td>\n",
       "      <td>2143630275</td>\n",
       "      <td>necesita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344546</td>\n",
       "      <td>depósito</td>\n",
       "      <td>nmp</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005820</td>\n",
       "      <td>depósitos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344657</td>\n",
       "      <td>precipitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005931</td>\n",
       "      <td>precipita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344674</td>\n",
       "      <td>corralito</td>\n",
       "      <td>n</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005948</td>\n",
       "      <td>corralito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344789</td>\n",
       "      <td>sencillo</td>\n",
       "      <td>j</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511861924</td>\n",
       "      <td>sencillos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345089</td>\n",
       "      <td>permitir</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862224</td>\n",
       "      <td>permita</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103923 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Lemma       POS SourceID     TokenID       Word\n",
       "98            nikita         o   431270  2206403194     Nikita\n",
       "110          escrito   jms       431270  2206403206    escrito\n",
       "321        calladito         j   431290  2074527333  calladita\n",
       "331           sólito   jms       431290  2074527343     sólito\n",
       "536        necesitar    vip-3s   431310  2143630275   necesita\n",
       "...              ...       ...      ...         ...        ...\n",
       "27344546    depósito   nmp       676040   250005820  depósitos\n",
       "27344657  precipitar    vip-3s   676040   250005931  precipita\n",
       "27344674   corralito         n   676040   250005948  corralito\n",
       "27344789    sencillo         j   676060  2511861924  sencillos\n",
       "27345089    permitir  vsp-1/3s   676060  2511862224    permita\n",
       "\n",
       "[103923 rows x 5 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_DF #It takes a while (which is expected because of the file sizes), but it works. I won't rerun the notebook\n",
    "      #because of the prior line but I've removed all extraneous cells for ease of reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_variety(es_DF,'ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>nikita</td>\n",
       "      <td>o</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403194</td>\n",
       "      <td>ES</td>\n",
       "      <td>Nikita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>escrito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403206</td>\n",
       "      <td>ES</td>\n",
       "      <td>escrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>calladito</td>\n",
       "      <td>j</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527333</td>\n",
       "      <td>ES</td>\n",
       "      <td>calladita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>sólito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527343</td>\n",
       "      <td>ES</td>\n",
       "      <td>sólito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>431310</td>\n",
       "      <td>2143630275</td>\n",
       "      <td>ES</td>\n",
       "      <td>necesita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22146901</td>\n",
       "      <td>sencillo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779969779</td>\n",
       "      <td>ES</td>\n",
       "      <td>sencilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147017</td>\n",
       "      <td>permitir</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779969895</td>\n",
       "      <td>ES</td>\n",
       "      <td>permita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147166</td>\n",
       "      <td>inscrito</td>\n",
       "      <td>j</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970044</td>\n",
       "      <td>ES</td>\n",
       "      <td>inscrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147196</td>\n",
       "      <td>visita</td>\n",
       "      <td>nfp</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970074</td>\n",
       "      <td>ES</td>\n",
       "      <td>visitas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147206</td>\n",
       "      <td>visita</td>\n",
       "      <td>nfp</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970084</td>\n",
       "      <td>ES</td>\n",
       "      <td>visitas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719752 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lemma       POS SourceID     TokenID Variety       Word\n",
       "98           nikita         o   431270  2206403194      ES     Nikita\n",
       "110         escrito   jms       431270  2206403206      ES    escrito\n",
       "321       calladito         j   431290  2074527333      ES  calladita\n",
       "331          sólito   jms       431290  2074527343      ES     sólito\n",
       "536       necesitar    vip-3s   431310  2143630275      ES   necesita\n",
       "...             ...       ...      ...         ...     ...        ...\n",
       "22146901   sencillo   jfs      1891249  1779969779      ES   sencilla\n",
       "22147017   permitir  vsp-1/3s  1891249  1779969895      ES    permita\n",
       "22147166   inscrito         j  1891249  1779970044      ES   inscrito\n",
       "22147196     visita   nfp      1891249  1779970074      ES    visitas\n",
       "22147206     visita   nfp      1891249  1779970084      ES    visitas\n",
       "\n",
       "[1719752 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_DF  #It appears the order of the columns was shuffled for some reason. I will fix this once I have constructed \n",
    "       #the final data frame object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spain is ready, now I have to do the same for the remaning 20 countries. This will take me some time, but I don't expect the code above to run into issues as the files are all in the same format. Below are the corpus directories for the remaining countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_dir = glob.glob(corpus_dir + 'wlp_AR-tez/*.txt') #Argentina\n",
    "bo_dir = glob.glob(corpus_dir + 'wlp_BO-teh/*.txt') #Bolivia\n",
    "cl_dir = glob.glob(corpus_dir + 'wlp_CL-wts/*.txt') #Chile\n",
    "co_dir = glob.glob(corpus_dir + 'wlp_CO-pem/*.txt') #Colombia\n",
    "cr_dir = glob.glob(corpus_dir + 'wlp_CR-jfh/*.txt') #Costa Rica\n",
    "cu_dir = glob.glob(corpus_dir + 'wlp_CU-rag/*.txt') #Cuba\n",
    "do_dir = glob.glob(corpus_dir + 'wlp_DO-egn/*.txt') #Dominican Republic\n",
    "ec_dir = glob.glob(corpus_dir + 'wlp_EC-jss/*.txt') #Ecuador\n",
    "gt_dir = glob.glob(corpus_dir + 'wlp_GT-miv/*.txt') #Guatemala\n",
    "hn_dir = glob.glob(corpus_dir + 'wlp_HN-paj/*.txt') #Honduras\n",
    "mx_dir = glob.glob(corpus_dir + 'wlp_MX-vzo/*.txt') #Mexico\n",
    "ni_dir = glob.glob(corpus_dir + 'wlp_NI-exu/*.txt') #Nicaragua\n",
    "pa_dir = glob.glob(corpus_dir + 'wlp_PA-qlz/*.txt') #Panama\n",
    "pe_dir = glob.glob(corpus_dir + 'wlp_PE-tae/*.txt') #Peru\n",
    "pr_dir = glob.glob(corpus_dir + 'wlp_PR-epz/*.txt') #Puerto Rico\n",
    "py_dir = glob.glob(corpus_dir + 'wlp_PY-ukd/*.txt') #Paraguay\n",
    "sv_dir = glob.glob(corpus_dir + 'wlp_SV-xkl/*.txt') #El Salvador\n",
    "us_dir = glob.glob(corpus_dir + 'wlp_US-ufh/*.txt') #The US\n",
    "uy_dir = glob.glob(corpus_dir + 'wlp_UY-nde/*.txt') #Uruguay\n",
    "#ve_dir = glob.glob(corpus_dir + 'wlp_VE-wsc/*.txt') #Venezuela. This file (ironically) doesn't work. I'll have to \n",
    "                                                       #go to the LMC and try to get a new copy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On to buiilding data frames. For this purpose, I have created a master function that goes through all of the steps above. I'll run each country in one cell so that memory and time limitations won't be exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_process(fdir, country_df, variety):\n",
    "    \"\"\"Builds, cleans, and creates a data frame using all files from the corpus directory and\n",
    "    keeping only rows of interest. fdir corresponds to the directory of the country, country_df\n",
    "    is a string and corresponds to an empty data frame to be populated, variety is also a string\n",
    "    and correspond to the variety being processed.\"\"\"\n",
    "    country_df = pd.DataFrame(columns=['SourceID', 'TokenID', 'Word', 'Lemma', 'POS'])\n",
    "    for fname in fdir:                         \n",
    "        df = toDF(fname)                           \n",
    "        df = remove_nondims(df)\n",
    "        country_df = pd.concat([country_df, df], sort=True)\n",
    "    add_variety(country_df, variety)\n",
    "    return country_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argentina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(ar_dir, 'ar_DF', 'AR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolivia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(bo_dir, 'bo_DF', 'BO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(cl_dir, 'cl_DF', 'CL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colombia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(co_dir, 'co_DF', 'CO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costa Rica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(cr_dir, 'cr_DF', 'CR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_proces(cu_dir, 'cu_DF', 'CU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominican Republic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(dr_dir, 'dr_DF', 'DR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecuador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(ec_dir, 'ec_DF', 'EC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guatemala:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_DF = corpus_process(gt_dir, 'gt_DF', 'GT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honduras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(hn_dir, 'hn_DF', 'HN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mexico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(mx_dir, 'mx_DF', 'MX')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicaragua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(ni_dir, 'ni_DF', 'NI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(pa_dir, 'pa_DF', 'PA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(pe_dir, 'pe_DF', 'PE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puerto Rico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(pr_dir, 'pr_DF', 'PR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(py_dir, 'py_DF', 'PY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Salvador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(sv_dir, 'sv_DF', 'SV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(us_dir, 'us_DF', 'US')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_process(uy_dir, 'uy_DF', 'UY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Venezuela:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_process(ve_dir, 've_DF', 'VE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- That's the end of this stage. I now have a preliminary data frame for each country that I can later put together into a larger one. I still want to keep the individual country data frames, though, for by-country analysis and processing or in case I notice an issue down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Storing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So that I don't have to rerun the whole notebook each time (or in case I want to use the resulting data frames in a different notebook), it makes sense to save the results in their current state. For this I'll make use of the pickle library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Argentina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_DF.to_pickle('ar_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolivia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bo_DF.to_pickle('bo_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colombia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_DF.to_pickle('co_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_DF.to_pickle('cl_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Costa Rica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_DF.to_pickle('cl_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cu_DF.to_pickle('cu_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dominican Republic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_DF.to_pickle('do_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecuador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_DF.to_pickle('ec_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guatemala:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_DF.to_pickle('gt_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honduras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hn_DF.to_pickle('hn_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mexico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx_DF.to_pickle('mx_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicaragua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_DF.to_pickle('ni_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Panama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_DF.to_pickle('pa_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_DF.to_pickle('pe_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puerto Rico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_DF.to_pickle('pr_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_DF.to_pickle('pa_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_DF.to_pickle('es_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Salvador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv_DF.to_pickle('sv_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_DF.to_pickle('us_DF.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ur_DF.to_pickle('ur_DF.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
