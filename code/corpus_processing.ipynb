{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diminutive Suffix Productivity\n",
    "Juan Berrios | jeb358@pitt.edu | Last updated: March 17, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary and overview of the data:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The purpose of the code included in this notebook is to build `DataFrame` objects from the `.txt` files in the corpus directories. I also do some preliminary data cleaning. The corpus I am using is the [*Corpus del español*](https://www.corpusdelespanol.org/); more specifically the [Web/Dialects](https://www.corpusdelespanol.org/web-dial/) corpus. While the corpus is searchable online, it is also possible to access the full data set for those wishing to do computational analyses, such as this. It is necessary to purchase a license to do so. I am authorized to use it through the license of the [Department of Linguistics](https://www.linguistics.pitt.edu/). Samples for the different formats can be downloaded from the [official website](https://www.corpusdata.org/formats.asp). I have also uploaded a copy of the free sample in the [data samples  directory](https://github.com/Data-Science-for-Linguists-2020/Diminutive-Suffix-Productivity/tree/master/data_samples) of this repository. The data set is available in three formats: (i) Database (Structured Query Language), (ii) Word/lemma/PoS, and (iii) linear (raw) text. All are `.txt` files and the former two are tab-delimited. I have chosen to work with the second format because the tags will come in handy and because it's quite compatible with Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Contents:**\n",
    "- [Section 1](###1.-Preparation)  includes the necessary preparations.\n",
    "- [Section 2](###2.-Loading-files)  includes code for loading the files and turning them into data frames using one of the `.txt` file as a sample.\n",
    "- [Section 3](###3.-Processing-corpus-directories)  includes code for performing the operations on a corpus directory containing all the text files of one variety.\n",
    "- [Section 4](###4.-Storing-files)  includes code for storing the resulting data frames as pickled files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading libraries and additional settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned OFF\n"
     ]
    }
   ],
   "source": [
    "#Importing libraries\n",
    "import glob, pickle, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Turning pretty print off:\n",
    "%pprint\n",
    "\n",
    "#Releasing all output:                                            \n",
    "from IPython.core.interactiveshell import InteractiveShell #Prints all commands rather than the last one.\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `txt` files are very large. For testing purposes, I'll use only one of them as a start. The files are also tab-delimited, which makes my job a little easier. The columns correspond to an ID for the source text, an ID for the token, the token (word), the lemma, and the POS. I will hence use those for column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = '../../Diminutive-Suffix-Productivity/private/data/wlp_ES-sbo/es-b-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['SourceID', 'TokenID', 'Word', 'Lemma', 'POS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First row is ignored because it corresponds to an identifier for the .txt file.\n",
    "\n",
    "df = pd.read_csv(fname,sep='\\t',encoding ='iso-8859-1',skiprows=[0],header=None,names=cols) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27345213, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #It's a very large file (27345213 rows). It will get much smaller once I start cleaning up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SourceID     TokenID  Word Lemma      POS\n",
       "0    431270  2206403096  Este  este      dd-\n",
       "1    431270  2206403097    es   ser   vip-3s\n",
       "2    431270  2206403098    un    un    li-ms\n",
       "3    431270  2206403099  blog  blog  nms    \n",
       "4    431270  2206403100    de    de        e"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)   #The lemma column will be useful when I need to aggregations that put lowecase and uppercase \n",
    "            #as well as plural and singular forms together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345212</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862347</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "27345212    676060  2511862347                         .   \n",
       "\n",
       "                             Lemma       POS  \n",
       "27345208                       mas        cc  \n",
       "27345209               información         n  \n",
       "27345210                   visitar  vsp-1/3s  \n",
       "27345211  www.dineroabundancia.com         n  \n",
       "27345212                        $.         y  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12560728</td>\n",
       "      <td>554710</td>\n",
       "      <td>1012050429</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25161571</td>\n",
       "      <td>658620</td>\n",
       "      <td>799549379</td>\n",
       "      <td>Pandilla</td>\n",
       "      <td>pandilla</td>\n",
       "      <td>nfs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25349054</td>\n",
       "      <td>659670</td>\n",
       "      <td>932940257</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15941911</td>\n",
       "      <td>583600</td>\n",
       "      <td>724041365</td>\n",
       "      <td>(</td>\n",
       "      <td>par-l</td>\n",
       "      <td>y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3361630</td>\n",
       "      <td>467990</td>\n",
       "      <td>1786426227</td>\n",
       "      <td>mismo</td>\n",
       "      <td>mismo</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID      Word     Lemma      POS\n",
       "12560728    554710  1012050429         .        $.        y\n",
       "25161571    658620   799549379  Pandilla  pandilla  nfs    \n",
       "25349054    659670   932940257        un        un    li-ms\n",
       "15941911    583600   724041365         (     par-l        y\n",
       "3361630     467990  1786426227     mismo     mismo        r"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5) #Everything seems to be loaded correctly as of now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dd-', 'vip-3s', 'li-ms', 'nms    ', 'e', 'nfp    ', 'y',\n",
       "       'nfs    ', 'nmp    ', 'vsp-1/3s', 'n', 'cc', 'o', 'r', 'vps-ms',\n",
       "       'ld-fs', 'm$', 'vc-1/3s', 'vr', 'po', 'li-fs', 'ld-mp', 'vip-3p',\n",
       "       'ld-ms', 'jms    ', 'vpp', 'mc', 'vps-fs', 'j', 'vii-1/3s', 'e_21',\n",
       "       'x', nan, 'cs', 'ld', 'v', 'cc-', 'ld-fp', 'pi-0cn', 'dd',\n",
       "       'dxmp-ind-', 'vip-2s', 'dp-', 'vsp-3p', 'pi-0ms', 'jfp    ',\n",
       "       'cS_21', 'cS_22', 'jmp    ', 'vsp-2s', 'vip-1s', 'vsp-1p', 'ps',\n",
       "       'vip-1p/vis-1p', 'vip-1p', 'pd-3cs', 'vif-1p', 'vps-mp', 'vif-3s',\n",
       "       'vif-3p', 'jfs    ', 'dxfs-ind-', 'vsj-1/3s', 'i', 'pi-3ms',\n",
       "       'vis-3s', 'b', 'p', 'np', 'pr-3cn\"', 'px', 'dxms-ind-', 'pi-3cs',\n",
       "       'dxfs-', 'pr-3cs', 'px-ms', 'dxfp-ind-', 'vis-3p', 'li-mp', 'pi',\n",
       "       'vsi-3p', 'px-mp', 'vsi-1/3s', 'pq-3cn\"', 'vif-2s', 'vif-2p',\n",
       "       'vsp-2p', 'vip-2p', 'vpp-00', 'vm-2p', 'vis-1p', 'dxcs-ind-',\n",
       "       'pr-3cp', 'dxcs-dem-', 'vif-1s', 'vc-1p', 'cC_21', 'cC_22',\n",
       "       'vps-fp', 'vii-3p', 'pq-3cn', 'e_32', 'vis-1s', 'pr-0mp', 'pr-3fs',\n",
       "       'vc-3p', 'vii-1p', 'pv', 'nj', 'fn', 'vc-2p', 'vsi-2s', 'li-fp',\n",
       "       'pp-1cs', 'dxfp-', 'vsi-1p', 'vii-2s', 'vis-2s', 'pr-3ms', 'e_22',\n",
       "       'mo-ms-', 'jn', 'pr-3mp', 'cS_31', 'cS_32', 'cS_33', 'pq-3cp',\n",
       "       'dxfp-int-', 'vii-2p', 'vsj-3p', 'pp-2cs', 'vm-2s', 'pp-2cp', 'fj',\n",
       "       'mo', 'pr-3fs\"', 'pq-3cs', 'f', 'dxcp-dem-', 'e_43', 'vm-3p', 'fv',\n",
       "       'vc-2s', 'pq-3ms', 'fp', 'pron', 'prep', 'mo-fs-', 'pr-3fp',\n",
       "       'vis-2p', 'vm-3s', 'vsf-1/3s', 'e_31', 'vsi-2p', 'mo-mp-', 'N',\n",
       "       'pd-3ms', 'vsj-1p', 'xp', 'dxmp-int-', 'xs', 'xx', 'vsj-2s', 'fx',\n",
       "       'cS_41', 'cS_42', 'cS_43', 'cS_44', 'vsf-3p', 'e_33', 'px-00',\n",
       "       'vsj-2p', 'e_42', 'fnp', 'x_sp', 'pp-2p', 'fnj', 'xe', 'dxfs-int-',\n",
       "       'vsf-2s', 'dxcp-ind-', 'pd-3fs', 'pd-3fp', 'pd-3mp', 'PN_MISC',\n",
       "       'v51    ', 'li', 'de', 'mo-fp-', 'fe', 'xb', 'v29    ', 'v30    ',\n",
       "       'vsf-2p', 'dp', 'ADJ', 'pn', 'xa', 'xy', 'xw', 'm', 'xh', 'xd',\n",
       "       'vsf-1p', 'vsp-', 'a', 'xm'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['POS'].unique()  #These POS tags are not very transparent, but it's a good start. These will also come \n",
    "                    #handy for data clean up because diminutivization applies only to some classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Variety'] = 'ES' #Time to add a column for the variety of Spanish. In this case Spain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SourceID     TokenID  Word Lemma      POS Variety\n",
       "0    431270  2206403096  Este  este      dd-      ES\n",
       "1    431270  2206403097    es   ser   vip-3s      ES\n",
       "2    431270  2206403098    un    un    li-ms      ES\n",
       "3    431270  2206403099  blog  blog  nms          ES\n",
       "4    431270  2206403100    de    de        e      ES"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #It works out well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345212</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862347</td>\n",
       "      <td>.</td>\n",
       "      <td>$.</td>\n",
       "      <td>y</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "27345212    676060  2511862347                         .   \n",
       "\n",
       "                             Lemma       POS Variety  \n",
       "27345208                       mas        cc      ES  \n",
       "27345209               información         n      ES  \n",
       "27345210                   visitar  vsp-1/3s      ES  \n",
       "27345211  www.dineroabundancia.com         n      ES  \n",
       "27345212                        $.         y      ES  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>23859409</td>\n",
       "      <td>644890</td>\n",
       "      <td>2343014538</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10021654</td>\n",
       "      <td>532990</td>\n",
       "      <td>1786645392</td>\n",
       "      <td>gratis</td>\n",
       "      <td>gratis</td>\n",
       "      <td>jms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25918237</td>\n",
       "      <td>665520</td>\n",
       "      <td>507420331</td>\n",
       "      <td>panzers</td>\n",
       "      <td>panzer</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17728027</td>\n",
       "      <td>591680</td>\n",
       "      <td>2280544516</td>\n",
       "      <td>Como</td>\n",
       "      <td>como</td>\n",
       "      <td>r</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13070606</td>\n",
       "      <td>558910</td>\n",
       "      <td>1559326864</td>\n",
       "      <td>basaba</td>\n",
       "      <td>basar</td>\n",
       "      <td>vii-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID     Word   Lemma       POS Variety\n",
       "23859409    644890  2343014538        a       a         e      ES\n",
       "10021654    532990  1786645392   gratis  gratis   jms          ES\n",
       "25918237    665520   507420331  panzers  panzer         n      ES\n",
       "17728027    591680  2280544516     Como    como         r      ES\n",
       "13070606    558910  1559326864   basaba   basar  vii-1/3s      ES"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A first step involved in cleaning up the data is to remove rows that are not necessary for this analysis. There are two main things to tackle first: symbols and '@' that are stand-ins for words that were removed from the corpus for copyright reasons when it was created. For the former, I can make use of the POS column. Symbols are tagged 'y'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['POS'] != 'y'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345207</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862342</td>\n",
       "      <td>obtener</td>\n",
       "      <td>obtener</td>\n",
       "      <td>vr</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24218955 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "0           431270  2206403096                      Este   \n",
       "1           431270  2206403097                        es   \n",
       "2           431270  2206403098                        un   \n",
       "3           431270  2206403099                      blog   \n",
       "4           431270  2206403100                        de   \n",
       "...            ...         ...                       ...   \n",
       "27345207    676060  2511862342                   obtener   \n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "\n",
       "                             Lemma       POS Variety  \n",
       "0                             este       dd-      ES  \n",
       "1                              ser    vip-3s      ES  \n",
       "2                               un     li-ms      ES  \n",
       "3                             blog   nms          ES  \n",
       "4                               de         e      ES  \n",
       "...                            ...       ...     ...  \n",
       "27345207                   obtener        vr      ES  \n",
       "27345208                       mas        cc      ES  \n",
       "27345209               información         n      ES  \n",
       "27345210                   visitar  vsp-1/3s      ES  \n",
       "27345211  www.dineroabundancia.com         n      ES  \n",
       "\n",
       "[24218955 rows x 6 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #It works. Looks like around 3,000,000 rows were removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since '@' is meant to replace words and not symbols, it is tagged as a noun, so the same strategy doesn't work. An alternative is to use the Word column instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Word'] != '@'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403096</td>\n",
       "      <td>Este</td>\n",
       "      <td>este</td>\n",
       "      <td>dd-</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403097</td>\n",
       "      <td>es</td>\n",
       "      <td>ser</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403098</td>\n",
       "      <td>un</td>\n",
       "      <td>un</td>\n",
       "      <td>li-ms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403099</td>\n",
       "      <td>blog</td>\n",
       "      <td>blog</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403100</td>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "      <td>e</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345207</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862342</td>\n",
       "      <td>obtener</td>\n",
       "      <td>obtener</td>\n",
       "      <td>vr</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345208</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862343</td>\n",
       "      <td>mas</td>\n",
       "      <td>mas</td>\n",
       "      <td>cc</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345209</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862344</td>\n",
       "      <td>informacion</td>\n",
       "      <td>información</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345210</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862345</td>\n",
       "      <td>visite</td>\n",
       "      <td>visitar</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345211</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862346</td>\n",
       "      <td>www.DineroAbundancia.com</td>\n",
       "      <td>www.dineroabundancia.com</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22958991 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID                      Word  \\\n",
       "0           431270  2206403096                      Este   \n",
       "1           431270  2206403097                        es   \n",
       "2           431270  2206403098                        un   \n",
       "3           431270  2206403099                      blog   \n",
       "4           431270  2206403100                        de   \n",
       "...            ...         ...                       ...   \n",
       "27345207    676060  2511862342                   obtener   \n",
       "27345208    676060  2511862343                       mas   \n",
       "27345209    676060  2511862344               informacion   \n",
       "27345210    676060  2511862345                    visite   \n",
       "27345211    676060  2511862346  www.DineroAbundancia.com   \n",
       "\n",
       "                             Lemma       POS Variety  \n",
       "0                             este       dd-      ES  \n",
       "1                              ser    vip-3s      ES  \n",
       "2                               un     li-ms      ES  \n",
       "3                             blog   nms          ES  \n",
       "4                               de         e      ES  \n",
       "...                            ...       ...     ...  \n",
       "27345207                   obtener        vr      ES  \n",
       "27345208                       mas        cc      ES  \n",
       "27345209               información         n      ES  \n",
       "27345210                   visitar  vsp-1/3s      ES  \n",
       "27345211  www.dineroabundancia.com         n      ES  \n",
       "\n",
       "[22958991 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df #Looks good, this removed about 1,500,000 more rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lastly, I only want to keep diminutivized forms for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['Word'].str[-3:] == 'ito') | (df['Word'].str[-3:] == 'ita')|   #Keeps only rows ending in the segments.\n",
    "  (df['Word'].str[-4:] == 'itos') | (df['Word'].str[-4:] == 'itas')|       #of interest. I will probably refine this. \n",
    "  (df['Word'].str[-4:] == 'illo') | (df['Word'].str[-4:] == 'illa')|       #later using regular expressions instead. \n",
    "  (df['Word'].str[-4:] == 'illos') | (df['Word'].str[-4:] == 'illas')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403194</td>\n",
       "      <td>Nikita</td>\n",
       "      <td>nikita</td>\n",
       "      <td>o</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403206</td>\n",
       "      <td>escrito</td>\n",
       "      <td>escrito</td>\n",
       "      <td>jms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527333</td>\n",
       "      <td>calladita</td>\n",
       "      <td>calladito</td>\n",
       "      <td>j</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527343</td>\n",
       "      <td>sólito</td>\n",
       "      <td>sólito</td>\n",
       "      <td>jms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>431310</td>\n",
       "      <td>2143630275</td>\n",
       "      <td>necesita</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344477</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005751</td>\n",
       "      <td>ladrillo</td>\n",
       "      <td>ladrillo</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344546</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005820</td>\n",
       "      <td>depósitos</td>\n",
       "      <td>depósito</td>\n",
       "      <td>nmp</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344657</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005931</td>\n",
       "      <td>precipita</td>\n",
       "      <td>precipitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27344674</td>\n",
       "      <td>676040</td>\n",
       "      <td>250005948</td>\n",
       "      <td>corralito</td>\n",
       "      <td>corralito</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27345089</td>\n",
       "      <td>676060</td>\n",
       "      <td>2511862224</td>\n",
       "      <td>permita</td>\n",
       "      <td>permitir</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95568 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SourceID     TokenID       Word       Lemma       POS Variety\n",
       "98          431270  2206403194     Nikita      nikita         o      ES\n",
       "110         431270  2206403206    escrito     escrito   jms          ES\n",
       "321         431290  2074527333  calladita   calladito         j      ES\n",
       "331         431290  2074527343     sólito      sólito   jms          ES\n",
       "536         431310  2143630275   necesita   necesitar    vip-3s      ES\n",
       "...            ...         ...        ...         ...       ...     ...\n",
       "27344477    676040   250005751   ladrillo    ladrillo   nms          ES\n",
       "27344546    676040   250005820  depósitos    depósito   nmp          ES\n",
       "27344657    676040   250005931  precipita  precipitar    vip-3s      ES\n",
       "27344674    676040   250005948  corralito   corralito         n      ES\n",
       "27345089    676060  2511862224    permita    permitir  vsp-1/3s      ES\n",
       "\n",
       "[95568 rows x 6 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This gets the data at to a first stage that's easier to work with. There are still many rows which do not belong in the data frame (e.g., verb forms other than gerunds that just happen to end in the same segment), but it will be more efficient to remove those when the full data frame is constructed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing corpus directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As a first step, knowing now that the operations above are sucessful, I will define functions to make the processing pipeline for the full data drame object more efficient and streamlined:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toDF(fname):\n",
    "    \"\"\"Turns tab-delimited file into a data frame\"\"\"\n",
    "    cols = ['SourceID', 'TokenID', 'Word', 'Lemma', 'POS']\n",
    "    df = pd.read_csv(fname,sep='\\t',encoding ='iso-8859-1',skiprows=[0],header=None,names=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variety(df,variety):\n",
    "    \"\"\"Adds a column specifying a given variety of Spanish to a data frame\"\"\"\n",
    "    df['Variety'] = variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_syms(df):\n",
    "    \"\"\"Excludes symbols\"\"\"\n",
    "    df = df[df['POS'] != 'y']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_redacted(df):\n",
    "    \"\"\"Excludes @ symbols, which stand for words that have been redacted for copyright reasons\"\"\"\n",
    "    df = df[df['Word'] != '@']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nondims(df):\n",
    "    \"\"\"Removes tokens that do not end in the segments of interest (-ito/-illo)\"\"\"\n",
    "    df = df[(df['Word'].str[-3:] == 'ito') | (df['Word'].str[-3:] == 'ita')|\n",
    "            (df['Word'].str[-4:] == 'itos') | (df['Word'].str[-4:] == 'itas')|\n",
    "            (df['Word'].str[-4:] == 'illo') | (df['Word'].str[-4:] == 'illa')|\n",
    "            (df['Word'].str[-4:] == 'illos') | (df['Word'].str[-4:] == 'illas')]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now let's set the directory. I'll start with the Spain directory, since I used a Spain text file for the test run in Section 2 above. In addition, Spain is by far the largest directory (over 3 GB when compressed), so if the code works fine for it, it should work for the rest of the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../Diminutive-Suffix-Productivity/private/data/wlp_ES-sbo\\\\es-b-0.txt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_dir = '../../Diminutive-Suffix-Productivity/private/data/'\n",
    "es_fname = glob.glob(corpus_dir + 'wlp_ES-sbo/*.txt')\n",
    "es_fname[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(es_fname) #There are 20 files in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [SourceID, TokenID, Word, Lemma, POS, Variety]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_DF = pd.DataFrame(columns=cols) #Builds a new, empty data frame object.\n",
    "es_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in es_fname:                         #Note that I'm only using one of the cleaning functions\n",
    "    df = toDF(fname)                           #because it gets me to the same end result. But the other ones   \n",
    "    df = remove_nondims(df)                    #might be useful down the road, which is why I defined them.\n",
    "    es_DF = pd.concat([es_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>nikita</td>\n",
       "      <td>o</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nikita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>escrito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403206</td>\n",
       "      <td>NaN</td>\n",
       "      <td>escrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>calladito</td>\n",
       "      <td>j</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>calladita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>sólito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sólito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>431310</td>\n",
       "      <td>2143630275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>necesita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22146901</td>\n",
       "      <td>sencillo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779969779</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sencilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147017</td>\n",
       "      <td>permitir</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779969895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>permita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147166</td>\n",
       "      <td>inscrito</td>\n",
       "      <td>j</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inscrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147196</td>\n",
       "      <td>visita</td>\n",
       "      <td>nfp</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>visitas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147206</td>\n",
       "      <td>visita</td>\n",
       "      <td>nfp</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970084</td>\n",
       "      <td>NaN</td>\n",
       "      <td>visitas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719752 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lemma       POS SourceID     TokenID Variety       Word\n",
       "98           nikita         o   431270  2206403194     NaN     Nikita\n",
       "110         escrito   jms       431270  2206403206     NaN    escrito\n",
       "321       calladito         j   431290  2074527333     NaN  calladita\n",
       "331          sólito   jms       431290  2074527343     NaN     sólito\n",
       "536       necesitar    vip-3s   431310  2143630275     NaN   necesita\n",
       "...             ...       ...      ...         ...     ...        ...\n",
       "22146901   sencillo   jfs      1891249  1779969779     NaN   sencilla\n",
       "22147017   permitir  vsp-1/3s  1891249  1779969895     NaN    permita\n",
       "22147166   inscrito         j  1891249  1779970044     NaN   inscrito\n",
       "22147196     visita   nfp      1891249  1779970074     NaN    visitas\n",
       "22147206     visita   nfp      1891249  1779970084     NaN    visitas\n",
       "\n",
       "[1719752 rows x 6 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_DF #It takes a while (which is expected because of the file sizes), but it works. I won't rerun the notebook\n",
    "      #because of the prior line but I've removed all extraneous cells for ease of reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_variety(es_DF,'ES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Variety</th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>nikita</td>\n",
       "      <td>o</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403194</td>\n",
       "      <td>ES</td>\n",
       "      <td>Nikita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>escrito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431270</td>\n",
       "      <td>2206403206</td>\n",
       "      <td>ES</td>\n",
       "      <td>escrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>calladito</td>\n",
       "      <td>j</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527333</td>\n",
       "      <td>ES</td>\n",
       "      <td>calladita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>331</td>\n",
       "      <td>sólito</td>\n",
       "      <td>jms</td>\n",
       "      <td>431290</td>\n",
       "      <td>2074527343</td>\n",
       "      <td>ES</td>\n",
       "      <td>sólito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>necesitar</td>\n",
       "      <td>vip-3s</td>\n",
       "      <td>431310</td>\n",
       "      <td>2143630275</td>\n",
       "      <td>ES</td>\n",
       "      <td>necesita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22146901</td>\n",
       "      <td>sencillo</td>\n",
       "      <td>jfs</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779969779</td>\n",
       "      <td>ES</td>\n",
       "      <td>sencilla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147017</td>\n",
       "      <td>permitir</td>\n",
       "      <td>vsp-1/3s</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779969895</td>\n",
       "      <td>ES</td>\n",
       "      <td>permita</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147166</td>\n",
       "      <td>inscrito</td>\n",
       "      <td>j</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970044</td>\n",
       "      <td>ES</td>\n",
       "      <td>inscrito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147196</td>\n",
       "      <td>visita</td>\n",
       "      <td>nfp</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970074</td>\n",
       "      <td>ES</td>\n",
       "      <td>visitas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22147206</td>\n",
       "      <td>visita</td>\n",
       "      <td>nfp</td>\n",
       "      <td>1891249</td>\n",
       "      <td>1779970084</td>\n",
       "      <td>ES</td>\n",
       "      <td>visitas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1719752 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Lemma       POS SourceID     TokenID Variety       Word\n",
       "98           nikita         o   431270  2206403194      ES     Nikita\n",
       "110         escrito   jms       431270  2206403206      ES    escrito\n",
       "321       calladito         j   431290  2074527333      ES  calladita\n",
       "331          sólito   jms       431290  2074527343      ES     sólito\n",
       "536       necesitar    vip-3s   431310  2143630275      ES   necesita\n",
       "...             ...       ...      ...         ...     ...        ...\n",
       "22146901   sencillo   jfs      1891249  1779969779      ES   sencilla\n",
       "22147017   permitir  vsp-1/3s  1891249  1779969895      ES    permita\n",
       "22147166   inscrito         j  1891249  1779970044      ES   inscrito\n",
       "22147196     visita   nfp      1891249  1779970074      ES    visitas\n",
       "22147206     visita   nfp      1891249  1779970084      ES    visitas\n",
       "\n",
       "[1719752 rows x 6 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_DF  #It appears the order of the columns was shuffled for some reason. I will fix this once I have constructed \n",
    "       #the final data frame object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Spain is ready, now I have to do the same for the remaning 20 countries. This will take me some time, but I don't expect the code above to run into issues as the files are all in the same format. Below are the corpus directories for the remaining countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_fname = glob.glob(corpus_dir + 'wlp_AR-tez/*.txt') #Argentina\n",
    "bo_fname = glob.glob(corpus_dir + 'wlp_BO-teh/*.txt') #Bolivia\n",
    "cl_fname = glob.glob(corpus_dir + 'wlp_CL-wts/*.txt') #Chile\n",
    "co_fname = glob.glob(corpus_dir + 'wlp_CO-pem/*.txt') #Colombia\n",
    "cr_fname = glob.glob(corpus_dir + 'wlp_CR-jfh/*.txt') #Costa Rica\n",
    "cu_fname = glob.glob(corpus_dir + 'wlp_CU-rag/*.txt') #Cuba\n",
    "do_fname = glob.glob(corpus_dir + 'wlp_DO-egn/*.txt') #Dominican Republic\n",
    "ec_fname = glob.glob(corpus_dir + 'wlp_EC-jss/*.txt') #Ecuador\n",
    "gt_fname = glob.glob(corpus_dir + 'wlp_GT-miv/*.txt') #Guatemala\n",
    "hn_fname = glob.glob(corpus_dir + 'wlp_HN-paj/*.txt') #Honduras\n",
    "mx_fname = glob.glob(corpus_dir + 'wlp_MX-vzo/*.txt') #Mexico\n",
    "ni_fname = glob.glob(corpus_dir + 'wlp_NI-exu/*.txt') #Nicaragua\n",
    "pa_fname = glob.glob(corpus_dir + 'wlp_PA-qlz/*.txt') #Panama\n",
    "pe_fname = glob.glob(corpus_dir + 'wlp_PE-tae/*.txt') #Peru\n",
    "pr_fname = glob.glob(corpus_dir + 'wlp_PR-epz/*.txt') #Puerto Rico\n",
    "py_fname = glob.glob(corpus_dir + 'wlp_PY-ukd/*.txt') #Paraguay\n",
    "sv_fname = glob.glob(corpus_dir + 'wlp_SV-xkl/*.txt') #El Salvador\n",
    "us_fname = glob.glob(corpus_dir + 'wlp_US-ufh/*.txt') #The US\n",
    "uy_fname = glob.glob(corpus_dir + 'wlp_UY-nde/*.txt') #Uruguay\n",
    "#ve_fname = glob.glob(corpus_dir + 'wlp_VE-wsc/*.txt') #Venezuela. This file (ironically) doesn't work. I'll have to \n",
    "                                                       #go to the LMC and try to get a new copy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's make sure all files are in the directories, as we did with Spain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ar_fname)\n",
    "len(bo_fname)\n",
    "len(cl_fname)\n",
    "len(co_fname)\n",
    "len(cr_fname)\n",
    "len(cu_fname)\n",
    "len(do_fname)\n",
    "len(ec_fname)\n",
    "len(gt_fname)\n",
    "len(hn_fname)\n",
    "len(mx_fname)\n",
    "len(ni_fname)\n",
    "len(pa_fname)\n",
    "len(pe_fname)\n",
    "len(pr_fname)\n",
    "len(py_fname)\n",
    "len(sv_fname)\n",
    "len(us_fname)\n",
    "len(uy_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- On to buiilding data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_DF = pd.DataFrame(columns=cols)\n",
    "bo_DF = pd.DataFrame(columns=cols)\n",
    "cl_DF = pd.DataFrame(columns=cols)\n",
    "co_DF = pd.DataFrame(columns=cols)\n",
    "cr_DF = pd.DataFrame(columns=cols)\n",
    "cu_DF = pd.DataFrame(columns=cols)\n",
    "do_DF = pd.DataFrame(columns=cols)\n",
    "ec_DF = pd.DataFrame(columns=cols)\n",
    "gt_DF = pd.DataFrame(columns=cols)\n",
    "hn_DF = pd.DataFrame(columns=cols)\n",
    "mx_DF = pd.DataFrame(columns=cols)\n",
    "ni_DF = pd.DataFrame(columns=cols)\n",
    "pa_DF = pd.DataFrame(columns=cols)\n",
    "pe_DF = pd.DataFrame(columns=cols)\n",
    "pr_DF = pd.DataFrame(columns=cols)\n",
    "py_DF = pd.DataFrame(columns=cols)\n",
    "sv_DF = pd.DataFrame(columns=cols)\n",
    "us_DF = pd.DataFrame(columns=cols)\n",
    "uy_DF = pd.DataFrame(columns=cols)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Argentina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in ar_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    ar_DF = pd.concat([ar_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bolivia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in bo_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    bo_DF = pd.concat([bo_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in cl_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    cl_DF = pd.concat([cl_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colombia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in co_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    co_DF = pd.concat([co_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Costa Rica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in cr_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    cr_DF = pd.concat([cr_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Cuba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in cu_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    cu_DF = pd.concat([cu_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dominican Republic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in do_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    do_DF = pd.concat([do_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Honduras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in hn_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    hn_DF = pd.concat([hn_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nicaragua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in ni_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    ni_DF = pd.concat([ni_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Panama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in pa_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    pa_DF = pd.concat([pe_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Peru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in pe_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    pe_DF = pd.concat([pe_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puerto Rico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in pr_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    pr_DF = pd.concat([pr_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in py_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    py_DF = pd.concat([py_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guatemala:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in gt_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    gt_DF = pd.concat([gt_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Salvador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in sv_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    sv_DF = pd.concat([sv_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in us_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    us_DF = pd.concat([us_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in uy_fname:                         \n",
    "    df = toDF(fname)                           \n",
    "    df = remove_nondims(df)                    \n",
    "    uy_DF = pd.concat([uy_DF, df], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding varieties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_variety(do_DF,'DO')\n",
    "add_variety(co_DF,'CO')\n",
    "add_variety(cl_DF,'CL')\n",
    "add_variety(cu_DF,'CU')\n",
    "add_variety(bo_DF,'BO')\n",
    "add_variety(cr_DF,'CR')\n",
    "add_variety(hn_DF,'HN')\n",
    "add_variety(ni_DF,'NI')\n",
    "add_variety(pa_DF,'PA')\n",
    "add_variety(pe_DF,'PE')\n",
    "add_variety(pr_DF,'PR')\n",
    "add_variety(py_DF,'PY')\n",
    "add_variety(sv_DF,'SV')\n",
    "add_variety(uy_DF,'UY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Storing files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So that I don't have to rerun the whole notebook each time (or in case I want to use the resulting data frames in a different notebook), it makes sense to save the results in their current state. For this I'll make use of the pickle library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('es_DF.pkl', 'wb')\n",
    "pickle.dump(es_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bolivia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('bo_DF.pkl', 'wb')\n",
    "pickle.dump(bo_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colombia:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('co_DF.pkl', 'wb')\n",
    "pickle.dump(co_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Chile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('cl_DF.pkl', 'wb')\n",
    "pickle.dump(cl_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Costa Rica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('cr_DF.pkl', 'wb')\n",
    "pickle.dump(cr_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('cu_DF.pkl', 'wb')\n",
    "pickle.dump(cu_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dominican Republic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('do_DF.pkl', 'wb')\n",
    "pickle.dump(do_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Honduras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('hn_DF.pkl', 'wb')\n",
    "pickle.dump(hn_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nicaragua:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('ni_DF.pkl', 'wb')\n",
    "pickle.dump(ni_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Panama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('pa_DF.pkl', 'wb')\n",
    "pickle.dump(pa_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Peru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('pe_DF.pkl', 'wb')\n",
    "pickle.dump(pe_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guatemala:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('gt_DF.pkl', 'wb')\n",
    "pickle.dump(gt_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puerto Rico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('pr_DF.pkl', 'wb')\n",
    "pickle.dump(pr_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paraguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('py_DF.pkl', 'wb')\n",
    "pickle.dump(py_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Salvador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('sv_DF.pkl', 'wb')\n",
    "pickle.dump(sv_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('us_DF.pkl', 'wb')\n",
    "pickle.dump(us_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uruguay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open ('uy_DF.pkl', 'wb')\n",
    "pickle.dump(uy_DF, f, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftoy = df.iloc[5000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftoy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\strings.py:1843: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "dftoy = dftoy[dftoy['Word'].str.contains(r'\\w*i(t|ll)(o|a)s?\\b')]   #Note word boundary is optional since\n",
    "                                                                    #the cells only contain one word. I'm keeping here\n",
    "                                                                    #in case I want to use the function on sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SourceID</th>\n",
       "      <th>TokenID</th>\n",
       "      <th>Word</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Variety</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7163</td>\n",
       "      <td>431560</td>\n",
       "      <td>615218396</td>\n",
       "      <td>favorito</td>\n",
       "      <td>favorito</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7658</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238236</td>\n",
       "      <td>sibaritas</td>\n",
       "      <td>sibarita</td>\n",
       "      <td>jmp</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7672</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238250</td>\n",
       "      <td>articulillo</td>\n",
       "      <td>articulillo</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7688</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238266</td>\n",
       "      <td>parrilla</td>\n",
       "      <td>parrilla</td>\n",
       "      <td>nfs</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7699</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238277</td>\n",
       "      <td>éxito</td>\n",
       "      <td>éxito</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7704</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238282</td>\n",
       "      <td>Pesadilla</td>\n",
       "      <td>pesadilla</td>\n",
       "      <td>nfs</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7905</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238483</td>\n",
       "      <td>éxito</td>\n",
       "      <td>éxito</td>\n",
       "      <td>n</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8131</td>\n",
       "      <td>431570</td>\n",
       "      <td>2427238709</td>\n",
       "      <td>tornillo</td>\n",
       "      <td>tornillo</td>\n",
       "      <td>nms</td>\n",
       "      <td>ES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SourceID     TokenID         Word        Lemma      POS Variety\n",
       "7163    431560   615218396     favorito     favorito  nms          ES\n",
       "7658    431570  2427238236    sibaritas     sibarita  jmp          ES\n",
       "7672    431570  2427238250  articulillo  articulillo        n      ES\n",
       "7688    431570  2427238266     parrilla     parrilla  nfs          ES\n",
       "7699    431570  2427238277        éxito        éxito        n      ES\n",
       "7704    431570  2427238282    Pesadilla    pesadilla  nfs          ES\n",
       "7905    431570  2427238483        éxito        éxito        n      ES\n",
       "8131    431570  2427238709     tornillo     tornillo  nms          ES"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftoy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
